#!/bin/bash

# ä½¿ç”¨æœ¬åœ°APIæœåŠ¡çš„æ•°æ®åˆæˆç®¡é“
# é€‚ç”¨äºå·²ç»éƒ¨ç½²ä¸ºAPIæœåŠ¡çš„æœ¬åœ°æ¨¡å‹

echo "ğŸš€ ä½¿ç”¨æœ¬åœ°APIæœåŠ¡çš„æ•°æ®åˆæˆç®¡é“"
echo "ğŸ“… $(date)"
echo "=================================================="

# è®¾ç½®ç¯å¢ƒå˜é‡ - æŒ‡å‘ä½ çš„æœ¬åœ°æ¨¡å‹APIæœåŠ¡
export COMPLETION_OPENAI_API_KEY="your-api-key-or-dummy"  # å¦‚æœä¸éœ€è¦å¯ä»¥è®¾ç½®ä¸ºdummy
export COMPLETION_OPENAI_BASE_URL="http://localhost:8000/v1"  # ä¿®æ”¹ä¸ºä½ çš„APIæœåŠ¡åœ°å€

# åŸºç¡€é…ç½®
DATA_DIR="data"
FILTERED_DATA_DIR="data_filtered_api"
OUTPUT_BASE="outputs_api"
INTERMEDIATE_DIR="${OUTPUT_BASE}/intermediate"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p ${OUTPUT_BASE}/{chunks,chunk4,topics,questions,validated_questions,answers,syndatas,stats}
mkdir -p ${INTERMEDIATE_DIR}

echo "ğŸ“ é…ç½®ä¿¡æ¯:"
echo "   APIåœ°å€: ${COMPLETION_OPENAI_BASE_URL}"
echo "   æ•°æ®ç›®å½•: ${DATA_DIR}"
echo "   è¾“å‡ºç›®å½•: ${OUTPUT_BASE}"
echo ""

# æ€§èƒ½é…ç½®
BATCH_SIZE=8  # APIæ¨¡å¼ä¸‹æ‰¹é‡å¤§å°è¦é€‚ä¸­
MAX_WORKERS=2

# è¿è¡Œç®¡é“ï¼ˆä¸ä½¿ç”¨vLLMï¼Œä½¿ç”¨APIï¼‰
echo "ğŸ”¥ è¿è¡Œæ•°æ®åˆæˆç®¡é“ï¼ˆAPIæ¨¡å¼ï¼‰"
python -m utils.syndata_pipeline_v5 \
  --data_dir "${DATA_DIR}" \
  --filtered_data_dir "${FILTERED_DATA_DIR}" \
  --chunks_path "${OUTPUT_BASE}/chunks/article_chunks_api.json" \
  --chunk4_path "${OUTPUT_BASE}/chunk4/article_chunk4_api.json" \
  --topics_path "${OUTPUT_BASE}/topics/article_topics_api.json" \
  --questions_path "${OUTPUT_BASE}/questions/article_questions_api.json" \
  --validated_questions_path "${OUTPUT_BASE}/validated_questions/article_questions_api_validated.json" \
  --answers_path "${OUTPUT_BASE}/answers/article_answers_api.json" \
  --syndatas_path "${OUTPUT_BASE}/syndatas/syndatas_api.json" \
  --start_idx 0 \
  --end_idx 10 \
  --max_workers ${MAX_WORKERS} \
  --batch_size ${BATCH_SIZE}

echo ""
echo "âœ… æ‰§è¡Œå®Œæˆï¼"
echo "ğŸ“Š è¾“å‡ºæ–‡ä»¶: ${OUTPUT_BASE}/syndatas/syndatas_api.json"
echo ""
echo "ğŸ’¡ æç¤ºï¼š"
echo "1. ç¡®ä¿ä½ çš„æœ¬åœ°APIæœåŠ¡æ­£åœ¨è¿è¡Œ"
echo "2. å¸¸è§çš„æœ¬åœ°APIæœåŠ¡:"
echo "   - vLLM: python -m vllm.entrypoints.openai.api_server --model /path/to/model"
echo "   - FastChat: python -m fastchat.serve.openai_api_server --model-path /path/to/model"
echo "   - Text Generation Inference: docker run --gpus all -p 8080:80 ghcr.io/huggingface/text-generation-inference:latest --model-id /path/to/model"
echo "3. APIæœåŠ¡é€šå¸¸åœ¨ http://localhost:8000 æˆ– http://localhost:8080"
echo ""
echo "ğŸ“… å®Œæˆæ—¶é—´: $(date)"
echo "=================================================="