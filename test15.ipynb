{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23cea46",
   "metadata": {},
   "source": [
    "# 向量库流程构建\n",
    "离线流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c267a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common_utils import load_articles, build_doubao_embedding\n",
    "from llama_index.core.schema import TextNode\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "        \n",
    "emb_model = build_doubao_embedding()\n",
    "def get_chunk_with_embedding(article_chunks, embedding_path):\n",
    "    for a_name, chunks in article_chunks.items():\n",
    "        print(f\"Processing {a_name}\")\n",
    "        chunk_texts = [chunk[\"chunk\"] for chunk in chunks]\n",
    "        response = emb_model(\n",
    "            # model=\"doubao-embedding-large-text-250515\",\n",
    "            model=\"doubao-embedding-text-240715\",\n",
    "            input=chunk_texts,\n",
    "            encoding_format=\"float\"\n",
    "        ) \n",
    "        chunks_with_embedding = []\n",
    "        for chunk, data in zip(chunks, response.data):\n",
    "            chunk[\"embedding\"] = data.embedding\n",
    "            chunk[\"doc_id\"] = str(uuid.uuid4())\n",
    "            chunks_with_embedding.append(chunk)\n",
    "        save_embeddings(chunks_with_embedding, embedding_path)\n",
    "    return chunks_with_embedding\n",
    "def save_embeddings(chunks_with_embedding, output_path):\n",
    "    # 判断 filename 是否存在，如果存在则追加写入，否则创建新文件\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, 'r', encoding=\"utf-8\") as f:\n",
    "            existing = json.load(f)\n",
    "        existing.extend(chunks_with_embedding)\n",
    "        with open(output_path, 'w', encoding=\"utf-8\") as f:\n",
    "            json_str = json.dumps(existing, ensure_ascii=False, indent=4)\n",
    "            json_str = json_str.replace(',\\n\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020', ', ')\n",
    "            f.write(json_str)\n",
    "            # json.dump(existing, f, ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        with open(output_path, 'w', encoding=\"utf-8\") as f:\n",
    "            json_str = json.dumps(chunks_with_embedding, ensure_ascii=False, indent=4)\n",
    "            # 替换掉 list 中的换行符，让 list 内容显示在一行\n",
    "            json_str = json_str.replace(',\\n\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020\\u0020', ', ')\n",
    "            f.write(json_str)\n",
    "    print(f\"Embedding saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6251cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2-对联苯-8-羟基喹啉锌...及其应用于新型白光OLED_赵婷_llm_correct.md\n",
      "Embedding saved to outputs_chunks/chunk_embedding08.json\n",
      "Processing 2.7”a-Si_TFT矩阵(英文)_熊绍珍_llm_correct.md\n",
      "Embedding saved to outputs_chunks/chunk_embedding08.json\n",
      "Processing 2005_OLED行业一瞥_王力_llm_correct.md\n",
      "Embedding saved to outputs_chunks/chunk_embedding08.json\n",
      "Processing 200mm×200mm_OLED步进投影曝光机_周畅_llm_correct.md\n",
      "Embedding saved to outputs_chunks/chunk_embedding08.json\n"
     ]
    }
   ],
   "source": [
    "article_chunks = load_articles(\"outputs_chunks/article_chunks06.json\")\n",
    "chunks_with_embedding = get_chunk_with_embedding(article_chunks, embedding_path=\"outputs_chunks/chunk_embedding08.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10c3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.schema import TextNode\n",
    "from utils.common_utils import load_articles\n",
    "\n",
    "def get_nodes(embedding_path):\n",
    "    chunks_with_embedding = load_articles(embedding_path)\n",
    "    chunks = chunks_with_embedding\n",
    "    nodes = []\n",
    "    for chunk in chunks:\n",
    "        node = TextNode(\n",
    "            text=chunk[\"chunk\"], \n",
    "            id=chunk[\"chunk_id\"], \n",
    "            doc_id=chunk[\"doc_id\"],\n",
    "            embedding=chunk[\"embedding\"],\n",
    "            metadata={\n",
    "                \"source\": chunk[\"source\"],\n",
    "            }\n",
    "        )\n",
    "        nodes.append(node)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8e9e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"outputs_chunks/chunk_embedding08.json\"\n",
    "allnodes = get_nodes(embedding_path)\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(allnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "\n",
    "# docstore.persist(persist_path=\"llama_index/docstore.json\")\n",
    "# docstore = SimpleDocumentStore.from_persist_path(\"llama_index/docstore.json\")\n",
    "db = chromadb.PersistentClient(path=\"llama_index/chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"sc_collection\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store, docstore=docstore)\n",
    "# index.storage_context.persist(persist_dir=\"./vector_index\")\n",
    "storage_context.persist(persist_dir=\"./vector_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aad3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c2bf6507-7b5a-4474-b58f-56f8bec05dcc',\n",
       " 'a2b2e4e3-0d15-4aeb-b577-a9e3b2dea74b',\n",
       " 'c95c7597-9fde-44f0-aecc-8c9b93e386e1',\n",
       " '7142332c-6373-4174-92a3-6e2ecdf4767f',\n",
       " 'f3e47c01-65a3-4027-aeb1-3a8c96a3cf45',\n",
       " '3993d0f1-2c72-44a9-a889-7a3b4afa5e42',\n",
       " '12ede737-13d4-410e-a929-b18294feabb8',\n",
       " '241cad18-5598-4799-b5c8-131facd634b7',\n",
       " 'b503d1b5-f7f7-4357-b97e-3d343f7420f9',\n",
       " 'e75b80fb-1616-4800-8f33-c21adef1f89e',\n",
       " 'baaa6088-fc0b-49fd-ac28-a2d7a4eccd67',\n",
       " '2af3ee24-858d-415b-b384-5591254a9e51',\n",
       " '64da9b40-17f9-4808-99b1-640559efc613',\n",
       " '32822fe6-ef30-4944-9ce2-3f6d930bb634',\n",
       " 'bca97f89-39f9-4404-9ea6-b81cb578113e',\n",
       " '071211c4-236e-4e23-9d39-2fbeea196d44',\n",
       " '5bcdbd89-34cb-4609-a2fc-adf8034539e3',\n",
       " '9a71fc40-9bfe-4415-a0dd-2aff23ab2a94',\n",
       " '18163620-e783-4469-bf0f-ff84124e53dd',\n",
       " '9afb4d3b-a539-45b5-b9aa-a35204305649',\n",
       " '51b2e0c3-9805-43bc-aba3-06ee33b8311f',\n",
       " 'f008e965-7b46-4d16-b3ff-a90b8cd97b41',\n",
       " '2afe7ed6-3eb1-4ca0-b981-8ee47fb70815',\n",
       " 'a2a3dd8a-2652-4178-b3ff-7d58ea5d6f0e',\n",
       " '25b2bc0a-8783-4e75-b52b-244287cf14fc',\n",
       " '301bdd28-1c03-418c-8189-bcf4abba45bd',\n",
       " '3db87aa3-190b-432a-8c7c-359d8fbfad0a',\n",
       " '16614b45-5d1e-4c6e-913a-bb489aefb8ed',\n",
       " 'c510c320-95fc-4153-acf6-f7a83772bb09',\n",
       " '6647dda5-1c7d-40a0-80f5-85ef1cd91eb8',\n",
       " 'cdb46dde-c200-4467-8728-f0ff25cb6eee',\n",
       " '2dfdd6d4-8bf4-4b94-8131-1ae3dc70db6c',\n",
       " '1ea7b5fc-d6ad-446c-bf34-cb995d9408c8',\n",
       " 'a8ef1762-62ed-4ff1-9f05-a6d8fde28ffc',\n",
       " '2dcb0e34-94cb-4962-973d-27ce59ee9af0',\n",
       " '3037438b-c331-4335-836b-eb760eada33c',\n",
       " '884eb91d-ba84-42b8-b993-7fd5a25d538c',\n",
       " 'eb7fe48c-1848-4ae8-94a5-0d6d374b520c',\n",
       " 'a61e076e-1321-4ed7-b241-269e2b589caa',\n",
       " 'ee3dbe00-6383-4c22-8c52-88fc5934858b',\n",
       " 'a3937eaa-b782-4512-863e-43c343b7ce31',\n",
       " 'cc7020a7-880f-40e7-9659-9ad442835e26',\n",
       " 'd376fb3c-a72c-44d5-92ed-ccc62c47aa69',\n",
       " '1511276b-6ba2-47a3-9da5-94be2fa809a5',\n",
       " 'ec459014-9872-49fa-8d46-7eaac386587d',\n",
       " '9eff85ef-982b-4b47-8ed8-a1a8648625a0',\n",
       " 'f59093a4-898c-4afe-b716-c45439a1e68b',\n",
       " '8f1c6843-5605-4f14-be6c-b024d0532c75',\n",
       " '9bae5deb-7e51-4e42-b35c-30e976614842',\n",
       " 'ccd7de5d-44cf-407f-a201-3e284f68b4ff',\n",
       " '4ac54f5f-6a71-4eeb-93e8-4a831bee7603',\n",
       " 'dfcc7dee-8b9c-45c1-86c5-c72c39166517',\n",
       " 'c67321fe-d520-44ec-9f10-25e675e67e6e',\n",
       " 'c380a5db-6e0c-4a14-8752-8595260a840a',\n",
       " 'd017bad6-81b7-42d7-a501-3b96ad3cedb7',\n",
       " '6247cd52-df0e-4085-9d0f-56489ff62712',\n",
       " '9b6f7ef2-0141-4505-bc46-a65fab557b7b',\n",
       " '4afd22d0-908d-42a0-8a02-5bdb25e6ad45',\n",
       " '08267586-a4d0-449a-9d86-e9b55605ecd0',\n",
       " '94e93dad-187b-479d-8f55-5e9071c1e822',\n",
       " 'd31d5d41-56bd-409d-a6a9-50253dcc216d',\n",
       " '1558c563-ad24-432a-879b-dd29b2a778e5',\n",
       " '3dc63fd1-bb50-458b-bb1c-02dc478397db',\n",
       " '67618be9-4289-434a-bd05-d3a3e88e9627',\n",
       " 'b52b12e3-6728-4006-b945-1e9f4e96d8aa',\n",
       " '186ee328-e87a-45bb-ba7d-8e0213939132',\n",
       " 'eebfa836-724b-4111-9bf3-9505c8cd83d6',\n",
       " '6909d373-d9e6-4fd2-a2c4-a06e1d1783d9',\n",
       " '27eecdb2-7fbc-41e5-8019-d6c9ea1eccf9',\n",
       " 'eee64af0-a1a2-4b2b-924c-9faad86d8790',\n",
       " 'e29d5b38-fc65-462f-adc3-bafa41106a38',\n",
       " 'f3351de5-429f-4374-a0b1-c53ffd4ecd02',\n",
       " '2b28260e-4b93-4d8f-ad56-2a84a8428cec',\n",
       " '10da2fd2-a984-4e82-ba28-e206f77488d6',\n",
       " '6e5324fe-5a1b-4e9e-9a14-c7100ac3d21a',\n",
       " '81cc0a62-c002-4dfb-b823-05b934525305',\n",
       " '38635247-8d9a-4acb-adee-c5b29c20274f',\n",
       " 'c5cf0e77-fb30-4ce2-a879-b84741d83ae5',\n",
       " '5d467c1a-e446-479b-ad74-a45d339cbbdb',\n",
       " 'de6a4b3f-e508-4ef6-aa14-b4240f8a4db8',\n",
       " 'c838e1eb-86f3-49f5-b60d-7443a3c234d9',\n",
       " '1c3c861b-f205-4163-b257-1cf9e581a4fb',\n",
       " '6b2a3e3a-b4cc-4ad6-ad77-478d20c62460',\n",
       " '360f5f1f-4a76-4393-a722-ad6765234e4c',\n",
       " '07a4c3ee-d5e2-48f2-8c84-7a8cff6c5799',\n",
       " '15f2cce9-5541-4710-8456-de2ce2a6603b',\n",
       " 'cdf4f40d-3d81-4fdb-a460-cd13333eacbc',\n",
       " '9b054813-4f2d-48a3-b1a1-692ef51b3898',\n",
       " '66f3fb63-3a24-41ef-8a08-f30d557a9f5a',\n",
       " 'ec87838a-18e3-4247-a387-471e2d3995a3',\n",
       " '8c5eb246-a2a7-4330-b053-90b70140c1e8',\n",
       " 'da1baed9-40ac-472e-af6a-b674ab6d46aa',\n",
       " '6da6f68a-55ad-42b5-9f6c-88103ba3b598',\n",
       " '933fc8a5-7458-4f37-8aad-b8c264275fde',\n",
       " 'a02a1a6f-6cd4-4530-ad39-473e92911879',\n",
       " '98787553-7d57-43c8-a55f-3b26c0ea356b',\n",
       " '2292ae1c-d642-4a4f-9178-44736cb5a7d9',\n",
       " '7de12bbf-ef71-407f-a7bf-c1d5b10cbd53',\n",
       " 'e9efcf10-920b-4957-ba13-688d59d30c35',\n",
       " '3d10bc0f-03f3-4725-984c-186defed9916',\n",
       " '25c8774d-c035-48d7-bca4-8411002acfe9',\n",
       " '0a472a63-80ec-4e3f-8ff2-1533f2eb2fbb',\n",
       " '279cecae-f1ed-4ff5-b107-b461d83a58c7',\n",
       " '7ff09c84-781f-4616-8782-8a7c70644e8c',\n",
       " 'f0261999-aa69-4b58-96c2-06ba45c36359',\n",
       " 'd3a5982f-9d25-4c17-b7b0-1368d687435b',\n",
       " '24093b9a-957d-482d-bc9c-740bc0f75a21',\n",
       " 'e439c41b-708e-41b2-9235-1a7b662c6187',\n",
       " '0aa3b8d9-b096-49f5-bfc5-32b580bd3f05',\n",
       " 'cd264568-5cbf-4195-bcd8-0df2a091732b',\n",
       " '5928605a-968f-478f-a9e6-1ddce357070d',\n",
       " 'b628447f-be4c-4cb0-8068-5cdd45d3fdcc',\n",
       " '4ae430c4-ea97-4841-aa42-0a8c1af3d775',\n",
       " 'bb8404e6-223c-400c-86e7-f4371f5593bf',\n",
       " 'a03aa635-5890-432f-b35a-9dc50b38a39f',\n",
       " 'da5a9784-3b8d-4ef0-92a4-c741ed6a407e',\n",
       " '879141e8-ed42-423e-8e82-304392a85a28',\n",
       " '9dfc4e8f-928e-49e0-8ff3-1b801a2ac49e',\n",
       " 'd4ac0e73-0ceb-4e3a-8eb9-2944f4e79497',\n",
       " '5305d048-ca88-491a-9321-28be82c796ac',\n",
       " 'cf9fb447-7cc7-478b-a7b2-205e1b86be47',\n",
       " '57b79030-715a-45f4-8729-4e5c10e89676',\n",
       " 'b8a13543-9b5e-4db6-a6a8-c6f51f40d257',\n",
       " '9b0df8f9-6f45-4e43-b4a7-8e88fbb7d6f5']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(allnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "\n",
    "embedding_model = OpenAIEmbedding(\n",
    "    model=\"doubao-embedding-text-240715\",\n",
    "    api_key=os.environ.get(\"COMPLETION_OPENAI_API_KEY\"),\n",
    "    api_base=os.environ.get(\"COMPLETION_OPENAI_BASE_URL\"),\n",
    ")\n",
    "Settings.embedding = embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    "    embed_model=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 index 永久化到 storage_context 中，并返回一个包含 index 的响应。\n",
    "index.storage_context.persist(persist_dir=\"./vector_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bd2b8",
   "metadata": {},
   "source": [
    "# 检索流程构建 \n",
    "在线流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2940b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding newlines for mmindex: 100%|██████████| 218k/218k [00:00<00:00, 43.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "embedding_path = \"outputs_chunks/chunk_embedding08.json\"\n",
    "allnodes = get_nodes(embedding_path)\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=allnodes,\n",
    "    # docstore=docstore,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "bm25_retriever.persist(\"llama_index/bm25_retriever.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_bm25_retriever = BM25Retriever.from_persist_dir(\"llama_index/bm25_retriever.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dca2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "\n",
    "docstore = SimpleDocumentStore.from_persist_path(\"llama_index/docstore.json\")\n",
    "db = chromadb.PersistentClient(path=\"llama_index/chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"sc_collection\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store, docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d837aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.base.embeddings.base import BaseEmbedding\n",
    "from utils.common_utils import build_doubao_embedding\n",
    "import os\n",
    "\n",
    "emb_model = build_doubao_embedding()\n",
    "class DouBaoEmbedding(BaseEmbedding):\n",
    "    def __init__(self, model_name: str = \"doubao-embedding-text-240715\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def _get_embedding(self, texts: list[str] | str) -> List[float] | List[List[float]]:\n",
    "        # 这里替换为实际调用豆包平台的 API 获取 embedding 的逻辑\n",
    "        # 例如通过 requests 请求、认证等\n",
    "        single_text = isinstance(texts, str)\n",
    "        if single_text:\n",
    "            texts = [texts]\n",
    "        response = emb_model(\n",
    "            model=self.model_name,\n",
    "            input=texts\n",
    "        )\n",
    "        embeddings = [\n",
    "            embedding_data.embedding for embedding_data in response.data\n",
    "        ]\n",
    "        if single_text:\n",
    "            return embeddings[0]\n",
    "        return embeddings  # 返回浮点数列表\n",
    "\n",
    "    async def _aget_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_embedding(text)\n",
    "\n",
    "    def _get_text_embedding(self, text: list[str]) -> List[List[float]]:\n",
    "        return self._get_embedding(text)\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_embedding(query)\n",
    "    async def _aget_text_embedding(self, text: list[str]) -> List[List[float]]:\n",
    "        return self._get_text_embedding(text)\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "embedding_model = DouBaoEmbedding(\n",
    "    model=\"doubao-embedding-text-240715\",\n",
    "    api_key=os.environ.get(\"COMPLETION_OPENAI_API_KEY\"),\n",
    "    api_base=os.environ.get(\"COMPLETION_OPENAI_BASE_URL\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5263c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    "    embed_model=embedding_model\n",
    ")\n",
    "\n",
    "vector_retriever = index.as_retriever(\n",
    "    similarity_top_k=10, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6665437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever,\n",
    ")\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core import QueryBundle\n",
    "from typing import List\n",
    "\n",
    "# 4. 创建自定义的检索器\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"custom retriever that performs both vector and keyword table retrieval\"\"\"\n",
    "    def __init__(self,\n",
    "                 vector_retriever: VectorIndexRetriever,\n",
    "                 bm25_retriever: BM25Retriever,\n",
    "                 mode: str = \"OR\",\n",
    "    ) -> None:\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._bm25_retriever = bm25_retriever\n",
    "        if mode not in [\"AND\", \"OR\"]:\n",
    "            raise ValueError(\"mode must be either AND or OR\")\n",
    "        self._mode = mode\n",
    "        super().__init__()\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"retrieve nodes given query\"\"\"\n",
    "        print(f\"Retrieving nodes for query: {query_bundle.query_str}\")\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        bm25_nodes = self._bm25_retriever.retrieve(query_bundle)\n",
    "        \n",
    "        vector_ids = {node.node.node_id for node in vector_nodes}\n",
    "        bm25_ids = {node.node.node_id for node in bm25_nodes}\n",
    "        \n",
    "        combined_dict = {node.node.node_id: node for node in vector_nodes}\n",
    "        combined_dict.update({node.node.node_id: node for node in bm25_nodes})\n",
    "        \n",
    "        if self._mode == \"AND\":\n",
    "            retrieve_ids = vector_ids.intersection(bm25_ids)\n",
    "        if self._mode == \"OR\":\n",
    "            retrieve_ids = vector_ids.union(bm25_ids)\n",
    "        \n",
    "        retrieve_nodes = [combined_dict[node_id] for node_id in retrieve_ids]\n",
    "        print(f\"{len(retrieve_nodes)} nodes retrieved\")\n",
    "        return retrieve_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1305d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving nodes for query: What is the capital of France?\n",
      "20 nodes retrieved\n"
     ]
    }
   ],
   "source": [
    "custom_retriever = CustomRetriever(\n",
    "    vector_retriever, \n",
    "    bm25_retriever, \n",
    ")\n",
    "retrieved_nodes = custom_retriever.retrieve(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c97c01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeWithScore(node=TextNode(id_='baaa6088-fc0b-49fd-ac28-a2d7a4eccd67', embedding=None, metadata={'source': '2-对联苯-8-羟基喹啉锌...及其应用于新型白光OLED_赵婷_llm_correct.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='这种利用空穴阻挡层来制备白光OLED 的方法, 工艺过程简单、器件稳定性好, 有利于工业化的大规模生产. # 1  实验部分', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cf6c2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baaa6088-fc0b-49fd-ac28-a2d7a4eccd67'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_nodes[0].node.node_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fde3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Who is the author of the book 'The Great Gatsby'?\",\n",
    "    \"What is the main character in 'The Great Gatsby'?\",\n",
    "    \"What is the setting of 'The Great Gatsby'?\",\n",
    "    \"What is the plot of 'The Great Gatsby'?\",\n",
    "    \"What is the theme of 'The Great Gatsby'?\",\n",
    "    \"What is the genre of 'The Great Gatsby'?\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
