{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a9da3c",
   "metadata": {},
   "source": [
    "# 流程验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa66b5e",
   "metadata": {},
   "source": [
    "### 嵌入流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_path=\"outputs_chunks/chunk09.json\"\n",
    "embeddings_path=\"outputs_embeddings/chunk_embedding09.json\"\n",
    "get_embedding_then_storage(chunks_path, embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vector_store import storage_embedding_nodes\n",
    "embeddings_path=\"outputs_embeddings/chunk_embedding09.json\"\n",
    "storage_embedding_nodes(embeddings_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据库中的node\n",
    "from utils.retrieve_nodes import get_query_engine, get_reranked_nodes\n",
    "from utils.data_synthesis import save_source_nodes\n",
    "\n",
    "question = \"2022年3月1日，中国和日本进行过一次贸易战，但最终中国胜过日本。\"\n",
    "query_engine = get_query_engine()\n",
    "source_nodes = get_reranked_nodes(question, query_engine)\n",
    "source_nodes2 = [\n",
    "    {\n",
    "        \"chunk\": node.node.text,\n",
    "        \"score\": node.score,\n",
    "        \"chunk_id\": node.node.node_id,\n",
    "        \"embedding\": node.node.embedding,\n",
    "    } for node in source_nodes\n",
    "]\n",
    "save_source_nodes(question, source_nodes2, \"outputs_syndatas/source_nodes01.json\")\n",
    "# 召回的文本块，id全都不存在于chunks中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f443bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d066ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes[0].__dict__[\"node\"].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 docstore 库中的内容 查看节点\n",
    "# 查看 vectorstore 库中的内容  查看向量\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "docstore_path = \"llama_index/docstore02.json\"\n",
    "docstore = SimpleDocumentStore.from_persist_path(docstore_path)\n",
    "docs = docstore.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_ls = list(docs)\n",
    "docs_ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_ls[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e329a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[docs_ls[1]].node.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[docs_ls[1]].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[docs_ls[1]].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b73452",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "chunk = {\n",
    "    \"chunk\": \"# 256级灰度OLED驱动电路\\n陈志明,朱文清,张志林,蒋雪茵 (上海大学材料科学与工程学院,上海201800)\\n摘　要：设计了一种OLED矩阵屏的驱动电路,在 $64\\\\times48$ 像素OLED矩阵屏上,采用脉宽调制的方法实现了256级灰度、无交叉效应的静态图案显示。通过在未选中行上施加正向偏压、未选中列上施加反向偏压的方法,有效地抑制了交叉效应。 关键词：有机电致发光；无源矩阵驱动；灰度显示\\n中图分类号：TN873.1文献标识码：A 文章编号：1001-5868(2005)02-0158-03\\n# 256Level Gray Scale OLED Driving Circuit\\nCHEN Zhi-ming, ZHU Wen-qing, ZHANG Zhi-lin, JIANG Xue-yin (School of Materials Science and Engineering, Shanghai University, Shanghai 201800, CHN)\",\n",
    "    \"source\": \"256级灰度OLED驱动电路_陈志明_llm_correct.md\",\n",
    "    \"chunk_id\": \"5e96c1a3-5135-4704-b0ea-814df80d4087\"\n",
    "}\n",
    "node = TextNode(\n",
    "    text=chunk[\"chunk\"], \n",
    "    id_=chunk[\"chunk_id\"], \n",
    "    metadata={\n",
    "        \"source\": chunk[\"source\"],\n",
    "    }\n",
    ")\n",
    "node.node_id , node.node_id == chunk[\"chunk_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ad7e5",
   "metadata": {},
   "source": [
    "### 合成流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d88177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda3\\envs\\raft\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: DLL load failed while importing _multiarray_umath: 找不到指定的模块。 (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19ff941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e409cf",
   "metadata": {},
   "source": [
    "# qwen-reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "def format_instruction(instruction, query, doc):\n",
    "    if instruction is None:\n",
    "        instruction = \"Given a query, retrieve relevant documents that can answer the query.\"\n",
    "    output = \"<Instruct>:{instruction}\\n<Query>:{query}\\n<Documents>:{doc}\".format(instruction=instruction, query=query, doc=doc)\n",
    "    return output\n",
    "\n",
    "def process_inputs(pairs):\n",
    "    inputs = tokenizer(\n",
    "        pairs, padding=False, truncation=\"longest_first\", return_attention_mask=False, \n",
    "        max_length=max_length - len(prefix_tokens) - len(suffix_tokens)\n",
    "    )\n",
    "    for i, ele in enumerate(inputs[\"input_ids\"]):\n",
    "        inputs[\"input_ids\"][i] = prefix_tokens + ele + suffix_tokens\n",
    "    inputs = tokenizer.pad(inputs, padding=True, return_tensors=\"pt\", max_length=max_length)\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(model.device)\n",
    "    return inputs\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_logits(inputs, **kwargs):\n",
    "    batch_scores = model(**inputs).logits[:, -1, :]\n",
    "    true_vector = batch_scores[:, token_true_id]\n",
    "    false_vector = batch_scores[:, token_false_id]\n",
    "    batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "    batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "    scores = batch_scores[:, 1].exp().tolist()\n",
    "    return scores\n",
    "\n",
    "model_name = \"Qwen/Qwen3-Reranker-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, attn_implemention=\"flash_attention_2\").cuda().eval()\n",
    "token_false_id = tokenizer.convert_tokens_to_ids(\"no\")\n",
    "token_true_id = tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "max_length = 2048\n",
    "\n",
    "prefix = \"<|im_start|>system\\nJudge whether the document meets the requirements based on the query and the instruct provided. Note that the answer can only be yes or no.<|im_end|\\n<im_start>user\\n\"\n",
    "suffix = \"<|im_end|\\n<im_start>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "prefix_tokens = tokenizer.encode(prefix, add_special_tokens=False)\n",
    "suffix_tokens = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "task = \"Given a query, retrieve relevant documents that answer the query.\"\n",
    "querires = [\n",
    "    \"what is the capital of China?\",\n",
    "    \"explain gravity\"\n",
    "]\n",
    "documents = [\n",
    "    \"the capital of China is Beijing.\",\n",
    "    \"gravity is a force that causes objects to fall toward the Earth's center.\"\n",
    "]\n",
    "pairs = [\n",
    "    format_instruction(task, query, document) for query, document in zip(querires, documents)\n",
    "]\n",
    "# tokenize the input texts\n",
    "inputs = process_inputs(pairs)\n",
    "scores = compute_logits(inputs)\n",
    "print(\"scores:\", scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
