#!/bin/bash

# æœ¬åœ°æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
# å±•ç¤ºå¦‚ä½•é…ç½®å’Œè¿è¡Œä¸åŒçš„æœ¬åœ°å¤§æ¨¡å‹

echo "ğŸš€ æœ¬åœ°æ¨¡å‹æ•°æ®åˆæˆç®¡é“ç¤ºä¾‹"
echo "=================================================="

# åŸºç¡€é…ç½®
DATA_DIR="data"
OUTPUT_BASE="outputs_local"
BATCH_SIZE=16
MAX_WORKERS=2

# ç¤ºä¾‹1: ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹ï¼ˆå¦‚æœè·¯å¾„å·²åœ¨vllm_client.pyä¸­é…ç½®ï¼‰
echo "ğŸ“Œ ç¤ºä¾‹1: ä½¿ç”¨é¢„å®šä¹‰çš„QwQ-32Bæ¨¡å‹"
echo "bashå‘½ä»¤:"
echo "python -m utils.syndata_pipeline_v5 \\"
echo "  --data_dir \"${DATA_DIR}\" \\"
echo "  --filtered_data_dir \"data_filtered_qwq\" \\"
echo "  --chunks_path \"${OUTPUT_BASE}/chunks/article_chunks_qwq.json\" \\"
echo "  --chunk4_path \"${OUTPUT_BASE}/chunk4/article_chunk4_qwq.json\" \\"
echo "  --topics_path \"${OUTPUT_BASE}/topics/article_topics_qwq.json\" \\"
echo "  --questions_path \"${OUTPUT_BASE}/questions/article_questions_qwq.json\" \\"
echo "  --validated_questions_path \"${OUTPUT_BASE}/validated_questions/article_questions_qwq_validated.json\" \\"
echo "  --answers_path \"${OUTPUT_BASE}/answers/article_answers_qwq.json\" \\"
echo "  --syndatas_path \"${OUTPUT_BASE}/syndatas/syndatas_qwq.json\" \\"
echo "  --start_idx 0 \\"
echo "  --end_idx 10 \\"
echo "  --use_vllm \\"
echo "  --model_name qwq_32 \\"
echo "  --gpu_memory_utilization 0.9 \\"
echo "  --tensor_parallel_size 4"
echo ""

# ç¤ºä¾‹2: ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„çš„Qwen2æ¨¡å‹
echo "ğŸ“Œ ç¤ºä¾‹2: ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„çš„Qwen2-7Bæ¨¡å‹"
echo "bashå‘½ä»¤:"
echo "python -m utils.syndata_pipeline_v5 \\"
echo "  --data_dir \"${DATA_DIR}\" \\"
echo "  --filtered_data_dir \"data_filtered_qwen2\" \\"
echo "  --chunks_path \"${OUTPUT_BASE}/chunks/article_chunks_qwen2.json\" \\"
echo "  --chunk4_path \"${OUTPUT_BASE}/chunk4/article_chunk4_qwen2.json\" \\"
echo "  --topics_path \"${OUTPUT_BASE}/topics/article_topics_qwen2.json\" \\"
echo "  --questions_path \"${OUTPUT_BASE}/questions/article_questions_qwen2.json\" \\"
echo "  --validated_questions_path \"${OUTPUT_BASE}/validated_questions/article_questions_qwen2_validated.json\" \\"
echo "  --answers_path \"${OUTPUT_BASE}/answers/article_answers_qwen2.json\" \\"
echo "  --syndatas_path \"${OUTPUT_BASE}/syndatas/syndatas_qwen2.json\" \\"
echo "  --start_idx 0 \\"
echo "  --end_idx 10 \\"
echo "  --use_vllm \\"
echo "  --model_name qwen2-7b \\"
echo "  --model_path \"/path/to/your/Qwen2-7B-Instruct\" \\"
echo "  --gpu_memory_utilization 0.9 \\"
echo "  --tensor_parallel_size 1 \\"
echo "  --max_model_len 32768"
echo ""

# ç¤ºä¾‹3: ä½¿ç”¨LLaMAæ¨¡å‹
echo "ğŸ“Œ ç¤ºä¾‹3: ä½¿ç”¨LLaMA-3-8Bæ¨¡å‹"
echo "bashå‘½ä»¤:"
echo "python -m utils.syndata_pipeline_v5 \\"
echo "  --data_dir \"${DATA_DIR}\" \\"
echo "  --filtered_data_dir \"data_filtered_llama\" \\"
echo "  --chunks_path \"${OUTPUT_BASE}/chunks/article_chunks_llama.json\" \\"
echo "  --chunk4_path \"${OUTPUT_BASE}/chunk4/article_chunk4_llama.json\" \\"
echo "  --topics_path \"${OUTPUT_BASE}/topics/article_topics_llama.json\" \\"
echo "  --questions_path \"${OUTPUT_BASE}/questions/article_questions_llama.json\" \\"
echo "  --validated_questions_path \"${OUTPUT_BASE}/validated_questions/article_questions_llama_validated.json\" \\"
echo "  --answers_path \"${OUTPUT_BASE}/answers/article_answers_llama.json\" \\"
echo "  --syndatas_path \"${OUTPUT_BASE}/syndatas/syndatas_llama.json\" \\"
echo "  --start_idx 0 \\"
echo "  --end_idx 10 \\"
echo "  --use_vllm \\"
echo "  --model_name llama3-8b \\"
echo "  --model_path \"/path/to/your/Meta-Llama-3-8B-Instruct\" \\"
echo "  --gpu_memory_utilization 0.9 \\"
echo "  --tensor_parallel_size 1"
echo ""

# ç¤ºä¾‹4: ä½¿ç”¨å®Œå…¨è‡ªå®šä¹‰çš„æ¨¡å‹
echo "ğŸ“Œ ç¤ºä¾‹4: ä½¿ç”¨å®Œå…¨è‡ªå®šä¹‰çš„æ¨¡å‹"
echo "bashå‘½ä»¤:"
echo "python -m utils.syndata_pipeline_v5 \\"
echo "  --data_dir \"${DATA_DIR}\" \\"
echo "  --filtered_data_dir \"data_filtered_custom\" \\"
echo "  --chunks_path \"${OUTPUT_BASE}/chunks/article_chunks_custom.json\" \\"
echo "  --chunk4_path \"${OUTPUT_BASE}/chunk4/article_chunk4_custom.json\" \\"
echo "  --topics_path \"${OUTPUT_BASE}/topics/article_topics_custom.json\" \\"
echo "  --questions_path \"${OUTPUT_BASE}/questions/article_questions_custom.json\" \\"
echo "  --validated_questions_path \"${OUTPUT_BASE}/validated_questions/article_questions_custom_validated.json\" \\"
echo "  --answers_path \"${OUTPUT_BASE}/answers/article_answers_custom.json\" \\"
echo "  --syndatas_path \"${OUTPUT_BASE}/syndatas/syndatas_custom.json\" \\"
echo "  --start_idx 0 \\"
echo "  --end_idx 10 \\"
echo "  --use_vllm \\"
echo "  --model_name custom \\"
echo "  --model_path \"/path/to/your/custom-model\" \\"
echo "  --gpu_memory_utilization 0.9 \\"
echo "  --tensor_parallel_size 2 \\"
echo "  --max_model_len 65536"
echo ""

echo "ğŸ’¡ æç¤ºï¼š"
echo "1. ä¿®æ”¹ --model_path ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„"
echo "2. æ ¹æ®GPUå†…å­˜è°ƒæ•´ --batch_size å’Œ --gpu_memory_utilization"
echo "3. æ ¹æ®GPUæ•°é‡è°ƒæ•´ --tensor_parallel_size"
echo "4. æ ¹æ®æ¨¡å‹èƒ½åŠ›è°ƒæ•´ --max_model_len"
echo ""
echo "ğŸ”§ å¸¸è§å‚æ•°è¯´æ˜ï¼š"
echo "  --model_name: æ¨¡å‹åç§°ï¼ˆqwq_32, qwen2-7b, llama3-8b, customç­‰ï¼‰"
echo "  --model_path: æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆåŒ…å«config.jsonç­‰æ–‡ä»¶ï¼‰"
echo "  --tensor_parallel_size: ä½¿ç”¨çš„GPUæ•°é‡"
echo "  --gpu_memory_utilization: GPUå†…å­˜ä½¿ç”¨ç‡ï¼ˆ0-1ä¹‹é—´ï¼‰"
echo "  --max_model_len: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦"
echo "  --batch_size: æ‰¹å¤„ç†å¤§å°"
echo "  --skip_document_filter: è·³è¿‡æ–‡æ¡£è´¨é‡ç­›é€‰"
echo "  --skip_question_validation: è·³è¿‡é—®é¢˜éªŒè¯"
echo ""
echo "=================================================="